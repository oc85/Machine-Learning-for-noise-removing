#  Image-to-Image Translation with Self-Attention using GANs for noise removal

__Description:__

This project involves developing a deep learning model for image-to-image translation using Generative Adversarial Networks (GANs) with a self-attention mechanism. The primary goal is to transform low-resolution images into high-resolution ones, improving image quality and clarity by leveraging GANs with self-attention layers to capture long-range dependencies within the images.

 __Key Components:__

 __Data Preprocessing:__
The dataset consists of pairs of low-resolution and high-resolution images. The images are loaded, resized, and normalized to prepare them for training.

 __Model Architecture:__
Generator: A U-Net inspired architecture with encoder-decoder pathways, incorporating self-attention layers to enhance feature representation by focusing on important regions of the image.
Discriminator: A convolutional network designed to distinguish between real high-resolution images and those generated by the generator.
Training Process:

The GAN framework trains the generator and discriminator in tandem. The generator aims to produce high-quality images that fool the discriminator, while the discriminator aims to correctly distinguish between real and generated images.
Loss functions used include Binary Cross-Entropy (BCE) for adversarial loss and Mean Absolute Error (MAE) for reconstruction loss.
Model Training and Evaluation:

The training loop involves multiple epochs, with checkpoints saved periodically to retain model states.
Visualization functions are included to monitor the training progress, showing sample outputs and loss curves.
Post-training Processing:

Once trained, the generator can be used to process new images, transforming them from lower to higher resolution with enhanced details.
Applications:

This model can be applied in domains requiring image enhancement, such as medical imaging, satellite imagery, or any field where improving image resolution and quality is crucial.

Training was performed on 256 images (without augmentation) during 5000 iterations on GPU:

![image](https://github.com/user-attachments/assets/5e541cb2-ba7e-4917-a0b1-be24e9dca968)


